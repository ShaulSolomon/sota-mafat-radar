{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvmafatvenv300c218a63dc4f9ea0765cbe246bbed9",
   "display_name": "Python 3.6.9 64-bit ('venv_mafat': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "\n",
    "WANDB_enable = False\n",
    "creds_path_ar = [\"../credentials.ini\",\"credentials.colab.ini\"]\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "        break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/shaul/workspace/GitHub/sota-mafat-radar\n"
    }
   ],
   "source": [
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from termcolor import colored\n",
    "\n",
    "from src.utils import experiment_utils as utils\n",
    "from src.utils import boilerplate\n",
    "\n",
    "from src.model_arch import arch_setup\n",
    "from src.model_arch import base_base_model\n",
    "from src.model_arch import alex_model\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mEverything is setup correctly\u001b[0m\n"
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = boilerplate.classic_trainval(PATH_ROOT,PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = arch_setup.DS(train_x,train_y)\n",
    "val_set= arch_setup.DS(val_x,val_y)\n",
    "\n",
    "train_loader=DataLoader(dataset= train_set, batch_size = 16, shuffle = True, num_workers = 2)\n",
    "val_loader=DataLoader(dataset= val_set, batch_size = 16, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "alex_mdf_s_model(\n  (features): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (3): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n    (7): ReLU(inplace=True)\n    (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (9): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n    (10): ReLU(inplace=True)\n    (11): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=4608, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1, bias=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model= alex_model.alex_mdf_s_model()\n",
    "# model.apply(init_weights)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "started training epoch no. 1\nepoch : 0.0000, loss : 46.3876, auc : 0.9833, acc : 0.9539, val_loss : 9.1840, val_auc : 0.9144, val_acc : 0.8382, \n---------------------------\n\nstarted training epoch no. 2\nepoch : 1.0000, loss : 46.8013, auc : 0.9829, acc : 0.9571, val_loss : 12.9453, val_auc : 0.9074, val_acc : 0.8479, \n---------------------------\n\nstarted training epoch no. 3\nepoch : 2.0000, loss : 49.3322, auc : 0.9848, acc : 0.9630, val_loss : 10.5864, val_auc : 0.9250, val_acc : 0.7864, \n---------------------------\n\nstarted training epoch no. 4\nepoch : 3.0000, loss : 42.7844, auc : 0.9866, acc : 0.9597, val_loss : 9.9262, val_auc : 0.9128, val_acc : 0.8414, \n---------------------------\n\nstarted training epoch no. 5\nepoch : 4.0000, loss : 36.2491, auc : 0.9891, acc : 0.9683, val_loss : 10.0610, val_auc : 0.9013, val_acc : 0.8155, \n---------------------------\n\nstarted training epoch no. 6\nepoch : 5.0000, loss : 27.3672, auc : 0.9940, acc : 0.9773, val_loss : 17.1822, val_auc : 0.9026, val_acc : 0.8414, \n---------------------------\n\nstarted training epoch no. 7\nepoch : 6.0000, loss : 41.3446, auc : 0.9899, acc : 0.9700, val_loss : 11.3055, val_auc : 0.9026, val_acc : 0.8026, \n---------------------------\n\nstarted training epoch no. 8\nepoch : 7.0000, loss : 3852.1628, auc : 0.5782, acc : 0.8951, val_loss : 951.2500, val_auc : 0.5000, val_acc : 0.5146, \n---------------------------\n\nstarted training epoch no. 9\nepoch : 8.0000, loss : 6062.5000, auc : 0.5000, acc : 0.8523, val_loss : 951.2500, val_auc : 0.5000, val_acc : 0.5146, \n---------------------------\n\nstarted training epoch no. 10\nepoch : 9.0000, loss : 6068.7500, auc : 0.5000, acc : 0.8523, val_loss : 978.7500, val_auc : 0.5000, val_acc : 0.5146, \n---------------------------\n\n"
    }
   ],
   "source": [
    "arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,device=device,train_y=train_y,val_y=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data,img in train_loader:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 1.96 GiB total capacity; 898.71 MiB already allocated; 111.81 MiB free; 930.00 MiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f59ece7a717f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march_setup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march_setup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 1.96 GiB total capacity; 898.71 MiB already allocated; 111.81 MiB free; 930.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "x1 = arch_setup.thresh(model(torch.from_numpy(train_x).to(device).type(torch.float32)).detach().cpu())\n",
    "x2 = arch_setup.thresh(model(torch.from_numpy(val_x).to(device).type(torch.float32)).detach().cpu())\n",
    "\n",
    "pred = [x1,x2]\n",
    "\n",
    "actual = [train_y, val_y]\n",
    "utils.stats(pred, actual)"
   ]
  }
 ]
}