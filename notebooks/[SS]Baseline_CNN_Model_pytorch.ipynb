{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "\n",
    "WANDB_enable = False\n",
    "creds_path_ar = [\"../credentials.ini\",\"credentials.colab.ini\"]\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "        break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asxyQmf6v_kR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4598,
     "status": "ok",
     "timestamp": 1597832311476,
     "user": {
      "displayName": "hezi hershkovitz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgOJkuWAegletuUtsxULlC1FGDiclvENmrkehoVQ=s64",
      "userId": "00324742314853373900"
     },
     "user_tz": -180
    },
    "id": "KGMVN1DcOSO6",
    "outputId": "ae4ddefa-66d8-40bb-8ee0-7da12c1546f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.6.0+cu101'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgWHU1hPwQBD"
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "\n",
    "WANDB_enable = False\n",
    "creds_path_ar = [\"../credentials.ini\",\"credentials.colab.ini\"]\n",
    "root_path = \"\"\n",
    "data_path = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "  if path.exists(creds_path):\n",
    "      config_parser = configparser.ConfigParser()\n",
    "      config_parser.read(creds_path)\n",
    "      root_path = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "      data_path = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "      WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "      ENV = config_parser['MAIN'][\"ENV\"]\n",
    "      break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "670_FFqYwZOy"
   },
   "outputs": [],
   "source": [
    "cd {root_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqKtI87lv_kb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from termcolor import colored\n",
    "\n",
    "from src.utils import experiment_utils as utils\n",
    "from src.utils import boilerplate\n",
    "\n",
    "from src.model_arch import arch_setup\n",
    "from src.model_arch import base_base_model\n",
    "<<<<<<< local\n",
    "<<<<<<< local\n",
    "from src.model_arch import alex_model\n",
    "=======\n",
    ">>>>>>> remote\n",
    "=======\n",
    ">>>>>>> remote\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "<<<<<<< local\n",
    "<<<<<<< local\n",
    "if :\n",
    "=======\n",
    "if torch.has_cuda:\n",
    ">>>>>>> remote\n",
    "=======\n",
    "if torch.has_cuda:\n",
    ">>>>>>> remote\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIstiDctv_kk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = boilerplate.classic_trainval(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM8U41sVv_ky"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fxhp0Vrpv_kz"
   },
   "outputs": [],
   "source": [
    "train_set = arch_setup.DS(train_x,train_y)\n",
    "val_set= arch_setup.DS(val_x,val_y)\n",
    "\n",
    "train_loader=DataLoader(dataset= train_set, batch_size = 16, shuffle = True, num_workers = 2)\n",
    "val_loader=DataLoader(dataset= val_set, batch_size = 16, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if (type(m) == nn.Linear) | (type(m) == nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model= base_base_model.base_base_model()\n",
    "model.apply(init_weights)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gt4qP9kv_lK"
   },
   "outputs": [],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "def init_weights(m):\n",
    "    if (type(m) == nn.Linear) | (type(m) == nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        #m.bias.data.fill_(0.01)\n",
    "\n",
    "model= base_base_model.base_base_model()\n",
    "model.apply(init_weights)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "#TODO: implement the Glorot Normal\n",
    "# init = tf.keras.initializers.GlorotNormal(seed = 0)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UWLzWL4v_lS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "_ = arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,device=device,train_y=train_y,val_y=val_y)\n",
    "=======\n",
    "_ = arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,train_y=train_y,val_y=val_y)\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gt4qP9kv_lK"
   },
   "outputs": [],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "def init_weights(m):\n",
    "    if (type(m) == nn.Linear) | (type(m) == nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        #m.bias.data.fill_(0.01)\n",
    "\n",
    "model= base_base_model.base_base_model()\n",
    "model.apply(init_weights)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "#TODO: implement the Glorot Normal\n",
    "# init = tf.keras.initializers.GlorotNormal(seed = 0)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UWLzWL4v_lS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "_ = arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,train_y=train_y,val_y=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cS3qPfeUv_le"
   },
   "outputs": [],
   "source": [
    "pred = [model(torch.from_numpy(train_x).to(device, dtype=torch.float)).detach().cpu().numpy(),\n",
    "        model(torch.from_numpy(val_x).to(device, dtype=torch.float)).detach().cpu().numpy()]\n",
    "actual = [train_y, val_y]\n",
    "utils.stats(pred, actual)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[SS]Baseline_CNN_Model_pytorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv_mafat': venv)",
   "name": "python36964bitvenvmafatvenva5f6ee7916d44380b4a924d34cc79db1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
