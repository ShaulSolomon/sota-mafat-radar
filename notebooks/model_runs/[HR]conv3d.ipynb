{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600781783346",
   "display_name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Trying to test to see how the modified Alex_Net model works on 3d input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "import wandb\n",
    "\n",
    "\n",
    "creds_path_ar = [\"../../credentials.ini\",\"credentials.colab.ini\"]\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "        break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)\n",
    "\n",
    "wandb.init(project=\"sota-mafat-base\")\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '[SS]Alexnet_pytorch'\n",
    "\n",
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from termcolor import colored\n",
    "\n",
    "from src.data import feat_data, get_data, get_data_pipeline\n",
    "from src.models import arch_setup, base_base_model, alex_model, base_3d\n",
    "from src.features import specto_feat\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['num_tracks'] = 3\n",
    "config['val_ratio'] = 3\n",
    "config['shift_segment'] = list(np.floor(np.linspace(1,31,10)).astype(int))\n",
    "config['get_shifts'] = True\n",
    "config['get_horizontal_flip'] = False\n",
    "config['get_vertical_flip'] = False\n",
    "config['wavelets'] = True\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(get_data_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = arch_setup.DS(train_x,train_y)\n",
    "val_set= arch_setup.DS(val_x,val_y)\n",
    "\n",
    "train_loader=DataLoader(dataset= train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "val_loader=DataLoader(dataset= val_set, batch_size = batch_size, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model= alex_model.alex_mdf_model()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if WANDB_enable == True:\n",
    "    runname = input(\"Enter WANDB runname(ENTER to skip wandb) :\")\n",
    "    notes = input(\"Enter run notes :\")\n",
    "\n",
    "    wandb.init(project=\"sota-mafat-base\",name=runname, notes=notes)\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = '[SS]Alexnet_pytorch'\n",
    "    \n",
    "    wandb.watch(model)\n",
    "    wandb.config['data_config'] = config\n",
    "    wandb.config['train_size'] = train_x.shape[0]\n",
    "    wandb.config['val_size'] = val_x.shape[0]\n",
    "    wandb.config['batch_size'] = batch_size\n",
    "    wandb.config['learning rate'] = lr\n",
    "    wandb.log(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log = arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,device=device,train_y=train_y,val_y=val_y, WANDB_enable = WANDB_enable, wandb= wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_setup.plot_loss_train_test(log,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_setup.plot_ROC_local_gpu(train_loader,val_loader,model,device)"
   ]
  }
 ]
}