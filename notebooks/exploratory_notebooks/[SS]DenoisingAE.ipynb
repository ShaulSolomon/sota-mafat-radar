{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvmafatvenv300c218a63dc4f9ea0765cbe246bbed9",
   "display_name": "Python 3.6.9 64-bit ('venv_mafat': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "import wandb\n",
    "\n",
    "\n",
    "creds_path_ar = [\"../../credentials.ini\",\"credentials.colab.ini\"]\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "        break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from src.visualization import specto_vis\n",
    "from termcolor import colored\n",
    "\n",
    "from src.data import feat_data, get_data\n",
    "from src.features import specto_feat\n",
    "from src.models import arch_setup, base_base_model, alex_model, tcn_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'MAFAT RADAR Challenge - Training Set V1'\n",
    "train_dict = get_data.load_data(train_path, PATH_DATA)\n",
    "\n",
    "#split Tracks here to only do augmentation on Train set\n",
    "# train_dict, val_dict = get_data.split_train_val_as_df(training_dict,ratio= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dict = get_data.load_data(PATH_DATA + 'MAFAT RADAR Challenge - Auxiliary Synthetic Set V2')\n",
    "synth_dict['segment_id'] = np.array(synth_dict['segment_id'].tolist()) - 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = specto_feat.data_preprocess(train_dict)\n",
    "synth_dict = specto_feat.data_preprocess(synth_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dicts(train_dict, synth_dict):\n",
    "    td = dict()\n",
    "    sd = dict()\n",
    "\n",
    "    seg_id = train_dict['segment_id']\n",
    "    iq_sb = train_dict['iq_sweep_burst']\n",
    "\n",
    "    for a,b in zip(seg_id,iq_sb):\n",
    "        td[a] = b\n",
    "\n",
    "    seg_id = synth_dict['segment_id']\n",
    "    iq_sb = synth_dict['iq_sweep_burst']\n",
    "\n",
    "    for a,b in zip(seg_id,iq_sb):\n",
    "        sd[a] = b\n",
    "\n",
    "    comb_dict = dict()\n",
    "\n",
    "    for key1,val1 in td.items():\n",
    "        if key1 in sd.keys():\n",
    "                val2 = sd[key1]\n",
    "                comb_dict[key1] = dict()\n",
    "                comb_dict[key1]['train_iq'] = val1\n",
    "                comb_dict[key1]['synth_iq'] = val2\n",
    "    \n",
    "    return comb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict = combine_dicts(train_dict, synth_dict)\n",
    "idx_val = np.random.choice(list(comb_dict.keys()), int(len(comb_dict.keys()) * 0.2), replace=False)\n",
    "idx_train = list(set(list(comb_dict.keys())).difference(set(idx_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_og = np.ndarray((1,126,32)) \n",
    "train_synth = np.ndarray((1,126,32)) \n",
    "val_og = np.ndarray((1,126,32)) \n",
    "val_synth = np.ndarray((1,126,32)) \n",
    "\n",
    "for key,val in comb_dict.items():\n",
    "    if key in idx_train:\n",
    "        train_og = np.concatenate((train_og, np.expand_dims(val['train_iq'],0)))\n",
    "        train_synth = np.concatenate((train_synth, np.expand_dims(val['synth_iq'],0)))\n",
    "    elif key in idx_val:\n",
    "        val_og = np.concatenate((val_og, np.expand_dims(val['train_iq'],0)))\n",
    "        val_synth = np.concatenate((val_synth, np.expand_dims(val['synth_iq'],0)))\n",
    "    else:\n",
    "        print(key)\n",
    "\n",
    "train_og = train_og[1:,:,:]\n",
    "train_synth = train_synth[1:,:,:]\n",
    "val_og = val_og[1:,:,:]\n",
    "val_synth = val_synth[1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_og.shape, val_synth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self,clean_df,noisy_df):\n",
    "        super().__init__()\n",
    "        self.clean_df = clean_df\n",
    "        self.noisy_df = noisy_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.noisy_df.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.noisy_df[idx]\n",
    "        x_hat = self.clean_df[idx]\n",
    "        return x, x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DS(train_og,train_synth)\n",
    "val_set = DS(val_og,val_synth)\n",
    "train_loader = DataLoader(dataset= train_set, batch_size = 32, shuffle = True, num_workers = 2)\n",
    "val_loader = DataLoader(dataset= val_set, batch_size = 32, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)  \n",
    "        self.conv2 = nn.Conv2d(32, 1, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.t_conv1 = nn.ConvTranspose2d(1, 32, 2, stride=2, output_padding=(1,0))\n",
    "        self.t_conv2 = nn.ConvTranspose2d(32, 1, 2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = self.t_conv2(x)\n",
    "        return x\n",
    "\n",
    "def sparse_loss(autoencoder, images):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        loss += torch.mean(torch.abs(values))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, padding=2)  \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32,64,5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.t_conv1 = nn.ConvTranspose2d(64, 32, 2, stride=2, output_padding=(1,0))\n",
    "        self.t_conv2 = nn.ConvTranspose2d(32, 16, 2, stride=2, output_padding=(1,0))\n",
    "        self.t_conv3 = nn.ConvTranspose2d(16,1,2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(self.conv3(x))\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.relu(self.t_conv2(x))\n",
    "        x = self.t_conv3(x)\n",
    "        return x\n",
    "\n",
    "def sparse_loss(model):\n",
    "    model_children = list(model.children())\n",
    "    loss = 0\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        loss += torch.mean(torch.abs(values))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder().to(device)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 126, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dirty, clean in train_loader:\n",
    "#     dirty = dirty.to(device).unsqueeze(1).type(torch.FloatTensor)\n",
    "#     out = model(dirty)\n",
    "\n",
    "#     print(\"Model input / output\")\n",
    "#     print(dirty.shape)\n",
    "#     print(out.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "epochs=100\n",
    "\n",
    "l=len(train_loader)\n",
    "v=len(val_loader)\n",
    "losslist=list()\n",
    "valloss = list()\n",
    "\n",
    "epochloss=0\n",
    "running_loss=0\n",
    "running_val_loss = 0\n",
    "reg_param = 1e-3\n",
    "\n",
    "add_sparsity = False\n",
    "add_regularity = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  \n",
    "  print(\"Entering Epoch: \",epoch)\n",
    "  for dirty,clean in tqdm((train_loader)):\n",
    "    dirty = dirty.to(device).unsqueeze(1).type(torch.FloatTensor)\n",
    "    clean = clean.to(device).unsqueeze(1).type(torch.FloatTensor)\n",
    "\n",
    "    output=model(dirty)\n",
    "    mse_loss=criterion(output,clean)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if add_sparsity:\n",
    "      l1_loss = sparse_loss(model, output)\n",
    "      loss = mse_loss + reg_param * l1_loss\n",
    "    else:\n",
    "      loss = mse_loss\n",
    "\n",
    "    if add_regularity:\n",
    "      l1_regularization, l2_regularization = torch.tensor(0).type(torch.FloatTensor), torch.tensor(0).type(torch.FloatTensor)\n",
    "      for param in model.parameters():\n",
    "        l1_regularization += torch.norm(param, 1)**2\n",
    "        l2_regularization += torch.norm(param, 2)**2\n",
    "\n",
    "      loss = loss + l1_regularization + l2_regularization\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    running_loss+=loss.item()\n",
    "    epochloss+=loss.item()\n",
    "\n",
    "  for dirty,clean in tqdm((val_loader)):\n",
    "    dirty = dirty.to(device).unsqueeze(1).type(torch.FloatTensor)\n",
    "    clean = clean.to(device).unsqueeze(1).type(torch.FloatTensor)\n",
    "\n",
    "    output=model(dirty)\n",
    "    mse_loss = criterion(output, clean)\n",
    "\n",
    "    if add_sparsity:\n",
    "        l1_loss = sparse_loss(model, output)\n",
    "        vloss = mse_loss + reg_param * l1_loss\n",
    "    else:\n",
    "        vloss = mse_loss\n",
    "    \n",
    "    running_val_loss += vloss.item()\n",
    "\n",
    "  #-----------------Log-------------------------------\n",
    "  losslist.append(running_loss / l)\n",
    "  valloss.append(running_val_loss / v)\n",
    "  running_loss = 0\n",
    "  running_val_loss = 0\n",
    "  print(\"======> epoch: {}/{}, Loss:{}\\tVal Loss:{}\".format(epoch,epochs,loss.item(),vloss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title(model._get_name())\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(losslist)),losslist,label=\"Train\")\n",
    "plt.plot(range(len(valloss)),valloss,label=\"Val\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "source": [
    "## Visualize how well model does"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(list(comb_dict.keys()),1)[0]\n",
    "train = comb_dict[idx]['train_iq']\n",
    "synth = comb_dict[idx]['synth_iq']\n",
    "cleaned = torch.from_numpy(train).to(device).view(1,1,126,32).type(torch.FloatTensor)\n",
    "cleaned = model(cleaned).view(126,32).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specto_vis.plot_spectrogram(train,None,color_map_path=\"/home/shaul/workspace/GitHub/sota-mafat-radar/data/cmap.npy\", figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specto_vis.plot_spectrogram(synth,None,color_map_path=\"/home/shaul/workspace/GitHub/sota-mafat-radar/data/cmap.npy\", figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specto_vis.plot_spectrogram(cleaned,None,color_map_path=\"/home/shaul/workspace/GitHub/sota-mafat-radar/data/cmap.npy\", figsize=(12,8));"
   ]
  }
 ]
}