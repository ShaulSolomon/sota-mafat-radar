{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599122241264",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path\n",
    "from os import path\n",
    "from importlib import reload\n",
    "import wandb\n",
    "\n",
    "\n",
    "creds_path_ar = [\"../../credentials.ini\",\"credentials.colab.ini\"]\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "        break\n",
    "\n",
    "if ENV==\"COLAB\":\n",
    "  from google.colab import drive\n",
    "  mount_path = '/content/gdrive/'\n",
    "  drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB_enable == True:\n",
    "    wandb.init(project=\"sota-mafat-base\")\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = '[SS]Alexnet_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from termcolor import colored\n",
    "\n",
    "from src.data import feat_data, get_data, get_data_pipeline\n",
    "from src.models import arch_setup, base_base_model, alex_model\n",
    "from src.features import specto_feat\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['num_tracks'] = 3\n",
    "config['val_ratio'] = 3\n",
    "config['shift_segment'] = list(np.arange(1,31))\n",
    "config['get_shifts'] = True\n",
    "config['get_horizontal_flip'] = True\n",
    "config['get_vertical_flip'] = True\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = get_data_pipeline.pipeline_trainval(PATH_ROOT+PATH_DATA, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_x.shape[0])\n",
    "print(val_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = arch_setup.DS(train_x,train_y)\n",
    "val_set= arch_setup.DS(val_x,val_y)\n",
    "\n",
    "train_loader=DataLoader(dataset= train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "val_loader=DataLoader(dataset= val_set, batch_size = batch_size, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model= alex_model.alex_mdf_model()\n",
    "# model.apply(init_weights)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if WANDB_enable == True:\n",
    "    runname = input(\"Enter WANDB runname(ENTER to skip wandb) :\")\n",
    "    notes = input(\"Enter run notes :\")\n",
    "\n",
    "    wandb.init(project=\"sota-mafat-base\",name=runname, notes=notes)\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = '[SS]Alexnet_pytorch'\n",
    "    \n",
    "    wandb.watch(model)\n",
    "    wandb.config['data_config'] = config\n",
    "    wandb.config['train_size'] = train_x.shape[0]\n",
    "    wandb.config['val_size'] = val_x.shape[0]\n",
    "    wandb.config['batch_size'] = batch_size\n",
    "    wandb.config['learning rate'] = lr\n",
    "    wandb.log(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log = arch_setup.train_epochs(train_loader,val_loader,model,criterion,optimizer,num_epochs= 10,device=device,train_y=train_y,val_y=val_y, WANDB_enable = WANDB_enable, wandb= wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_setup.plot_loss_train_test(log,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_setup.plot_ROC_local_gpu(train_loader,val_loader,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "alex_mdf_model(\n  (arch): AlexNet(\n    (features): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (4): ReLU(inplace=True)\n      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): ReLU(inplace=True)\n      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (9): ReLU(inplace=True)\n      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (11): ReLU(inplace=True)\n      (12): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n    (classifier): Sequential(\n      (0): Dropout(p=0.5, inplace=False)\n      (1): Linear(in_features=9216, out_features=4096, bias=True)\n      (2): ReLU(inplace=True)\n      (3): Dropout(p=0.5, inplace=False)\n      (4): Linear(in_features=4096, out_features=4096, bias=True)\n      (5): ReLU(inplace=True)\n      (6): Linear(in_features=4096, out_features=1, bias=True)\n    )\n  )\n)"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'MAFAT RADAR Challenge - Public Test Set V1'\n",
    "test_df = get_data.load_data(test_path, PATH_ROOT + PATH_DATA)\n",
    "test_df = specto_feat.data_preprocess(test_df.copy())\n",
    "test_x = test_df['iq_sweep_burst']\n",
    "test_x = test_x.reshape(list(test_x.shape)+[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with the probability prediction for each segment\n",
    "submission =  pd.DataFrame()\n",
    "submission['segment_id'] = test_df['segment_id']\n",
    "submission['prediction'] = model(torch.from_numpy(test_x).to(device).type(torch.float32)).detach().cpu().numpy()\n",
    "submission['prediction'] = submission['prediction'].astype('float')\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}