{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)",
   "display_name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c1e195df8d07db5ee7a78f454b46c3f2e14214bf8c9489d2db5cf8f372ff2ed"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Two Parts\n",
    "\n",
    "1. Run off the test data to get the test scores for a given model (to give us some indication of the accuracy)\n",
    "2. With the various models, create a LR using the test data as its own train/val."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "from os import path\n",
    "\n",
    "PATH_ROOT = \"\"\n",
    "PATH_DATA = \"\"\n",
    "\n",
    "creds_path_ar = [\"../../credentials.ini\", \"credentials.ini\"]\n",
    "\n",
    "for creds_path in creds_path_ar:\n",
    "    if path.exists(creds_path):\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser.read(creds_path)\n",
    "        PATH_ROOT = config_parser['MAIN'][\"PATH_ROOT\"]\n",
    "        PATH_DATA = config_parser['MAIN'][\"PATH_DATA\"]\n",
    "        WANDB_enable = config_parser['MAIN'][\"WANDB_ENABLE\"] == 'TRUE'\n",
    "        ENV = config_parser['MAIN'][\"ENV\"]\n",
    "\n",
    "# adding cwd to path to avoid \"No module named src.*\" errors\n",
    "sys.path.insert(0, os.path.join(PATH_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from src.data import get_data\n",
    "from src.data.iterable_dataset import Config, DataDict, StreamingDataset, iq_to_spectogram, \\\n",
    "    normalize\n",
    "from src.models import arch_setup, tcn_model3\n",
    "from src.data import get_data\n",
    "from src.visualization import metrics\n",
    "from src.features import specto_feat\n",
    "import wandb\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/ubuntu/sota-mafat-radar\n"
     ]
    }
   ],
   "source": [
    "%cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_paths = ['sota-mafat/sota-mafat-base/1epmi6lf','sota-mafat/sota-mafat-base/3s0bv1dr']\n",
    "test_path = 'MAFAT RADAR Challenge - FULL Public Test Set V1'\n",
    "final_test_path = 'MAFAT RADAR Challenge - Private Test Set V1'\n"
   ]
  },
  {
   "source": [
    "### PART 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str):\n",
    "    '''\n",
    "    Load Model from Wandb\n",
    "    '''\n",
    "    wandb.init()\n",
    "    wandb.restore('data/models/model.pth', run_path=model_path)\n",
    "    return torch.load(path.join(PATH_ROOT, 'wandb/latest-run/files/data/models/model.pth'))\n",
    "\n",
    "\n",
    "def load_testset(test_path: str):\n",
    "    '''\n",
    "    Load Test Data\n",
    "    '''\n",
    "    test_data = pd.DataFrame.from_dict(get_data.load_data(test_path, PATH_DATA), orient='index').transpose()\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def run_predictions(model, test_df, final_submission = False):\n",
    "    '''\n",
    "    Have the predictions ready for submission\n",
    "    '''\n",
    "    test_df['output_array'] = test_df['iq_sweep_burst'].progress_apply(iq_to_spectogram)\n",
    "    test_df['output_array'] = test_df.progress_apply(lambda row: specto_feat.max_value_on_doppler(row['output_array'], row['doppler_burst']), axis=1)\n",
    "    test_df['output_array'] = test_df['output_array'].progress_apply(normalize)\n",
    "    test_x = torch.from_numpy(np.stack(test_df['output_array'].tolist(), axis=0).astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu:0')\n",
    "\n",
    "    # Creating DataFrame with the probability prediction for each segment\n",
    "    submission = pd.DataFrame()\n",
    "    submission['segment_id'] = test_df['segment_id']\n",
    "    submission['prediction'] = model(test_x.to(device)).detach().cpu().numpy()\n",
    "    if not final_submission:\n",
    "        submission['label'] = test_df['target_type']\n",
    "    return submission\n",
    "\n",
    "def check_model_auc(local_model_path: str, test_path: str):\n",
    "    '''\n",
    "    1. Load the Model (using load_model())\n",
    "    2. Load the Test Data (using load_testdata())\n",
    "    3. Return the predictionsauc and acc scores of predictions\n",
    "    '''\n",
    "    model = load_local_model(local_model_path)\n",
    "    test_df = load_testset(test_path)\n",
    "    test_df['target_type'].replace({'animal': 0, 'human': 1}, inplace=True)\n",
    "    predictions = run_predictions(model, test_df)\n",
    "    return metrics.model_scores(predictions['label'], predictions['prediction'])\n",
    "\n",
    "def load_local_model(local_model_path: str):\n",
    "    return torch.load(path.join(PATH_ROOT, 'wandb', local_model_path, 'files/data/models/model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'sota-mafat/sota-mafat-base/2v6bs8kw'\n",
    "model_path2 = 'sota-mafat/sota-mafat-base/3s0bv1dr'\n",
    "model_path3 = 'sota-mafat/sota-mafat-tcn/2j8o99e4'\n",
    "# model_path4 = 'sota-mafat/sota-mafat-base/1wolsedh'\n",
    "\n",
    "local_model_paths = ['run-20201015_062929-j2ac4ecg','run-20201015_063004-3mp7hqo7','run-20201015_063022-3fscuvx1']\n",
    "# model = load_model(model_path)\n",
    "# test_path = 'MAFAT RADAR Challenge - FULL Public Test Set V1'\n",
    "# test_dict = load_testset(test_path)\n",
    "# predics = run_predicions(model, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 2607<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c6437c0450d4f25b8fb72c6e5abe88d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb/run-20201015_060728-rvahvuyd/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb/run-20201015_060728-rvahvuyd/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">faithful-sky-20</strong>: <a href=\"https://wandb.ai/sota-mafat/sota-mafat-radar/runs/rvahvuyd\" target=\"_blank\">https://wandb.ai/sota-mafat/sota-mafat-radar/runs/rvahvuyd</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.5<br/>\n                Syncing run <strong style=\"color:#cdcd00\">iconic-river-22</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/sota-mafat/sota-mafat-radar\" target=\"_blank\">https://wandb.ai/sota-mafat/sota-mafat-radar</a><br/>\n                Run page: <a href=\"https://wandb.ai/sota-mafat/sota-mafat-radar/runs/ld8sr36v\" target=\"_blank\">https://wandb.ai/sota-mafat/sota-mafat-radar/runs/ld8sr36v</a><br/>\n                Run data is saved locally in <code>wandb/run-20201015_061109-ld8sr36v</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2095.43it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3294.82it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13395.06it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7667262259281319"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "check_model_auc(model_path4,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "run-20201015_062929-j2ac4ecg\n",
      "100%|██████████| 284/284 [00:00<00:00, 2111.74it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3088.48it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12550.92it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.779084772682152"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "check_model_auc(local_model_paths[0], test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2092.41it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3209.40it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12739.51it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7667262259281319"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "check_model_auc(local_model_paths[1], test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2117.02it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2914.48it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12318.33it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7787373436569386"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "check_model_auc(local_model_paths[2], test_path)"
   ]
  },
  {
   "source": [
    "### PART 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_mean(model_paths: list, test_path, final_submission = False):\n",
    "    preds = []\n",
    "    test_df = load_testset(test_path)\n",
    "    test_df['target_type'].replace({'animal': 0, 'human': 1}, inplace=True)\n",
    "    for model_path in model_paths:\n",
    "        model = load_local_model(model_path)\n",
    "        pred = run_predictions(model, test_df, final_submission)\n",
    "        if pred['prediction'].min() < 0:\n",
    "            print(model_path)\n",
    "        preds.append(pred['prediction'])\n",
    "    df = pd.concat(preds, axis=1)\n",
    "    pred = df.mean(axis=1)\n",
    "    labels = test_df['target_type']\n",
    "    return metrics.model_scores(labels, pred), final_submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(model_paths: list, test_path, final_submission = False):\n",
    "    preds = []\n",
    "    scores = []\n",
    "    test_df = load_testset(test_path)\n",
    "    labels = test_df['target_type']\n",
    "    test_df['target_type'].replace({'animal': 0, 'human': 1}, inplace=True)\n",
    "    for model_path in model_paths:\n",
    "        model = load_local_model(model_path)\n",
    "        pred = run_predictions(model, test_df, final_submission)\n",
    "        preds.append(pred['prediction'])\n",
    "        if pred['prediction'].min() < 0:\n",
    "            print(model_path)\n",
    "        scores.append(metrics.model_scores(labels,pred['prediction']))\n",
    "    df = pd.concat(preds, axis=1)\n",
    "    scores = np.array(scores)\n",
    "    scores = scores / np.sum(scores)\n",
    "    weighted_mean = (scores*df).mean(axis=1)\n",
    "    return metrics.model_scores(labels, weighted_mean), scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(model_paths: list, test_path, final_submission=False):\n",
    "    preds = []\n",
    "    col_names = range(len(model_paths))\n",
    "    test_df = load_testset(test_path)\n",
    "    test_df['target_type'].replace({'animal': 0, 'human': 1}, inplace=True)\n",
    "    for model_path in model_paths:\n",
    "        model = load_local_model(model_path)\n",
    "        pred = run_predictions(model, test_df, final_submission)\n",
    "        if pred['prediction'].min() < 0:\n",
    "            print(model_path)\n",
    "        preds.append(pred['prediction'])\n",
    "    df = pd.concat(preds, axis=1)\n",
    "    df.columns = col_names \n",
    "    labels = test_df['target_type']\n",
    "    X_train, X_test,y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=43)\n",
    "    clf = LogR().fit(X_train,y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:,1]\n",
    "    print(clf.classes_)\n",
    "    # y_pred = (y_pred + 1) / 2\n",
    "    return metrics.model_scores(y_test, y_pred), clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2108.75it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3085.88it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13027.21it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2127.70it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3100.02it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12943.84it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2120.62it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3272.77it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12854.30it/s][0 1]\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8337438423645321, LogisticRegression())"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "lr_model(local_model_paths, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2182.93it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2963.80it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 14366.48it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2181.96it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2986.30it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 14526.26it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2170.04it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3290.76it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 14084.00it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8070776255707762, array([0.33515533, 0.3298388 , 0.33500587]))"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "weighted_mean(local_model_paths, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2149.91it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3222.70it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13827.48it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2139.61it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3185.79it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13700.88it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2141.51it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3099.82it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13586.18it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.7881773399014779,\n",
       " array([[1.71572887, 0.55828838, 0.45198532]]),\n",
       " array([-1.13894214]))"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "lr_model(local_model_paths, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble(model_paths, old_test_path, final_test_path, ensemble_method, final_submission= True):\n",
    "    preds = []\n",
    "    test_df = load_testset(final_test_path)\n",
    "    for model_path in model_paths:\n",
    "        model = load_local_model(model_path)\n",
    "        pred = run_predictions(model, test_df, final_submission)\n",
    "        preds.append(pred['prediction'])\n",
    "    \n",
    "    df = pd.concat(preds, axis=1)\n",
    "\n",
    "    if ensemble_method == \"weighted_mean\":\n",
    "        _, scores = weighted_mean(model_paths, old_test_path, final_submission)\n",
    "        prediction = (scores*df).sum(axis=1)\n",
    "    elif ensemble_method == \"lr_model\":\n",
    "        _, clf = lr_model(model_paths, old_test_path, True)\n",
    "        prediction = clf.predict_proba(df)[:,1]\n",
    "    else:\n",
    "        prediction = df.mean(axis=1)\n",
    "        \n",
    "    submission = pd.DataFrame()\n",
    "    test_df = pd.DataFrame.from_dict(get_data.load_data(final_test_path, PATH_DATA), orient='index').transpose()\n",
    "    submission['segment_id'] = test_df['segment_id']\n",
    "    submission['prediction'] = prediction\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 284/284 [00:00<00:00, 2105.00it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3206.27it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12577.15it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2120.50it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3260.24it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12722.23it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2127.91it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3152.62it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12851.39it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2113.72it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3215.10it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12880.29it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2129.44it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3255.37it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12588.05it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2113.07it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3225.56it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12451.34it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2129.84it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3208.16it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12943.98it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2119.56it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3227.04it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12763.94it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2108.29it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3093.72it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12482.26it/s]\n",
      "basic_mean\n",
      "100%|██████████| 248/248 [00:00<00:00, 2105.44it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3248.41it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 12679.95it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 2109.27it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3115.38it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 12910.52it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 2117.54it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3100.95it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 12270.70it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2068.15it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3157.21it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12838.78it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2117.53it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3065.51it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12414.10it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2112.13it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3219.50it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12413.84it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3e5d5bf8645b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_option\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-5628b0d9ff8c>\u001b[0m in \u001b[0;36mrun_ensemble\u001b[0;34m(model_paths, old_test_path, final_test_path, ensemble_method, final_submission)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mensemble_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lr_model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4d506795d2bb>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "all_options = ['basic_mean','weighted_mean','lr_model']\n",
    "best_score = 0\n",
    "best_option = None\n",
    "for option in all_options:\n",
    "    score = eval(option)(local_model_paths, test_path)\n",
    "    if score[0] > best_score:\n",
    "        best_score = score[0]\n",
    "        best_option = option\n",
    "\n",
    "print(best_option)\n",
    "\n",
    "submission = run_ensemble(local_model_paths, test_path, final_test_path, option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 248/248 [00:00<00:00, 2102.26it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3210.83it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 12324.64it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 2103.23it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3198.82it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 12672.39it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 2117.41it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 3067.19it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 13095.81it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2117.99it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3162.26it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12950.31it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2119.85it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3083.58it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 13013.55it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 2122.66it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 3207.53it/s]\n",
      "100%|██████████| 284/284 [00:00<00:00, 12922.49it/s]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "submission = run_ensemble(local_model_paths, test_path, final_test_path, 'lr_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      0.829345\n",
       "1      0.292620\n",
       "2      0.242568\n",
       "3      0.821355\n",
       "4      0.482799\n",
       "         ...   \n",
       "243    0.717627\n",
       "244    0.781365\n",
       "245    0.252067\n",
       "246    0.254729\n",
       "247    0.242621\n",
       "Name: prediction, Length: 248, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "submission['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('SOTA-MAFAT-Final2_lrmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}